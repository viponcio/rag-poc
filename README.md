# RAG Application with Express, Anthropic, and Supabase

This should be part 4 of the Technical Assessment, but rag and kag was new for me so I decided to study about it and I make a project about RAG. I learn rag from this youtube video https://www.youtube.com/watch?v=FCoGU072Bmc 

This repository contains a Retrieval-Augmented Generation (RAG) application built with Express.js, Anthropic's Claude AI, and Supabase vector database. The application can scrape web content, generate embeddings, store them in a database, and answer queries using relevant context.

## Overview

This application implements a basic RAG system that:
1. Scrapes content from a specified URL
2. Splits content into manageable chunks
3. Generates deterministic embeddings for each chunk
4. Stores content and embeddings in Supabase
5. Retrieves relevant context when a query is submitted
6. Uses Anthropic's Claude AI to generate answers based on the retrieved context

## Features

- Web scraping with Cheerio
- Document chunking with LangChain's text splitter
- Deterministic embedding generation (1536-dimensions)
- Vector similarity search in Supabase
- AI-powered Q&A with Anthropic's Claude

## Prerequisites

- Node.js
- Express.js
- Supabase account with vector database setup
- Anthropic API key

## Installation

1. Clone this repository:
```bash
git clone https://github.com/yourusername/your-repo-name.git
cd your-repo-name
```

2. Install dependencies:
```bash
npm install
```

3. Run locally:
```bash
npm run start
```

4. Create a `.env` file with the following environment variables:
```
ANTHROPIC_API_KEY=your_anthropic_api_key
SUPABASE_URL=your_supabase_url
SUPABASE_ANON_KEY=your_supabase_anon_key
```

## Database Setup

Set up a table in Supabase with the following structure:

```sql
create table doc (
  id bigint generated by default as identity primary key,
  content text,
  embedding vector(1536)
);

create function match_documents(query_embedding vector(1536), match_threshold float, match_count int)
returns table (
  id bigint,
  content text,
  similarity float
)
language plpgsql
as $$
begin
  return query
  select
    doc.id,
    doc.content,
    1 - (doc.embedding <=> query_embedding) as similarity
  from doc
  where 1 - (doc.embedding <=> query_embedding) > match_threshold
  order by similarity desc
  limit match_count;
end;
$$;
```

### Endpoints

#### 1. Generate and Store Embeddings
```bash
curl --request POST \
  --url http://localhost:3035/embed \
  --header 'Content-Type: application/json' \
  --header 'User-Agent: insomnia/11.0.2'
```
This endpoint fetches content from `https://www.inboxpurge.com/faq`, generates embeddings, and stores them in Supabase.

#### 2. Query for Information
```bash
curl --request POST \
  --url http://localhost:3035/query \
  --header 'Content-Type: application/json' \
  --header 'User-Agent: insomnia/11.0.2' \
  --data '{
	"query": "What email providers does the InboxPurge extension work with?"
}'
```
This endpoint takes a query, finds relevant context in the database, and uses Claude to generate a response.

## Implementation Details

### Embedding Generation

Instead of using a traditional embedding API, this application uses a deterministic approach to generate embeddings:

1. A SHA-256 hash is created from the text
2. The hash is used to generate 1536 values in the range [-1, 1]
3. The embedding is normalized to unit length

### Context Retrieval

When a query is received, the application:
1. Generates an embedding for the query
2. Finds the most similar documents in the database
3. Combines the context from these documents
4. Sends the context along with the query to Claude
5. Returns Claude's response
